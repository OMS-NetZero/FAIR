{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd60e964-4bba-41fc-abc3-ae2198a93ccc",
   "metadata": {},
   "source": [
    "# A calibrated, constrained ensemble\n",
    "\n",
    "FaIR, like every other simple or complex climate model, is naive. It will produce projections for whatever emissions/concentrations/forcing scenario you ask it to produce projections for. It is up to the user to determine whether these projections are useful and sensible.\n",
    "\n",
    "We are [developing a set of parameter calibrations](https://github.com/chrisroadmap/fair-calibrate) that reproduce both observed climate change since pre-industrial and assessed climate metrics such as the equilibrium climate sensitivity from the IPCC Sixth Assessement Report.\n",
    "\n",
    "The calibrations will be continually updated, as new data for surface temperature, ocean heat content, external forcing and emissions become available. For now, we have an IPCC AR6 WG1 version (where observational constraints are generally up to somewhere in the 2014 to 2020 period), and assessments of emergent climate metrics are from the IPCC AR6 WG1 Chapter 7. We use emissions data (historical + SSP) from the Reduced Complexity Model Intercomparison Project which was compiled for IPCC AR6 WG3 Chapter 3. We also have calibration versions for replacing historical CO2 emissions by Global Carbon Project estimates. This is v1.1.0 of the `fair-calibrate` package, and can be obtained from the DOI link below.\n",
    "\n",
    "A two-step constraining process is produced. The first step ensures that historical simulations match observed climate change to a root-mean-square error of less than 0.16°C. The second step simultaneously distribution-fits to the following assessed ranges:\n",
    "\n",
    "- equilibrium climate sensitivity (ECS), very likely range 2-5°C, best estimate 3°C\n",
    "- transient climate response (TCR), very likely range 1.2-2.4°C, best estimate 1.8°C\n",
    "- global mean surface temperature change 1850-1900 to 1995-2014, very likely range 0.67-0.98°C, best estimate 0.85°C\n",
    "- effective radiative forcing from aerosol-radiation interactions 1750 to 2005-2014, very likely range -0.6 to 0 W/m², best estimate -0.3 W/m²\n",
    "- effective radiative forcing from aerosol-cloud interactions 1750 to 2005-2014, very likely range -1.7 to -0.3 W/m², best estimate -1.0 W/m²\n",
    "- effective radiative forcing from aerosols 1750 to 2005-2014, very likely range -2.0 to -0.6 W/m², best estimate -1.3 W/m²\n",
    "- ocean heat content change 1971 to 2018, likely range 329-463 ZJ, best estimate 396 ZJ\n",
    "- CO2 concentrations in 2014, very likely range 396.95-398.15 ppm, best estimate 397.55 ppm\n",
    "- future warming in SSP245 1995-2014 to 2081-2100, 1.24-2.59°C, best estimate 1.81°C. Note the IPCC constraint was concentration driven, in fair-calibrate v1.1.0 an emissions-driven constraint was used.\n",
    "\n",
    "1001 posterior ensemble members are produced from an initial prior of 1.5 million.\n",
    "\n",
    "There are many, many, many different calibration and constraining possibilities, and it depends on your purposes as to what is appropriate. If you care about the carbon cycle, you might want to constrain on TCRE and ZEC in addition, or instead of, some of the other constraints above. Not all constraints are necessarily internally consistent, and there will be some tradeoff; it is impossible to hit the above ranges perfectly. As more constraints are added, this gets harder, or will require larger prior sample sizes.\n",
    "\n",
    "<a href=\"https://doi.org/10.5281/zenodo.7694879\"><img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.7694879.svg\" align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4bc63e",
   "metadata": {},
   "source": [
    "## 0. Get required imports\n",
    "\n",
    "[pooch](https://www.fatiando.org/pooch/latest/) is a useful package that allows downloads of external datasets to your cache, meaning that you don't have to include them in Git repositories (particularly troublesome for large files) or `.gitignore` them (difficult for exact reproduciblity, and easy to forget and accidently commit a large file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a38578-9f38-48f2-b961-7fb9c8f266b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pooch\n",
    "\n",
    "from fair import FAIR\n",
    "from fair.interface import fill, initialise\n",
    "from fair.io import read_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e41fa4",
   "metadata": {},
   "source": [
    "## 1. Create FaIR instance\n",
    "\n",
    "To reproduce an AR6-like run, we want to allow methane lifetime to be affected by all its relevant chemical precursors (NOx, VOCs, etc) so we set the `ch4_method` flag to `Thornhill2021` (see https://docs.fairmodel.net/en/latest/api_reference.html#fair.FAIR for all of the options for initialising `FAIR`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FAIR(ch4_method=\"Thornhill2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbabef9",
   "metadata": {},
   "source": [
    "## 2. Define time horizon\n",
    "\n",
    "A lot of analysis uses 2100 as the time horizon, but 2300 is an interesting end point to see the effects of long-term climate change. We'll set 2300 as the last time bound, so the last emissions time point is 2299.5. We could even run to 2500, as the scenarios are defined that far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.define_time(1750, 2300, 1)  # start, end, step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a91fce",
   "metadata": {},
   "source": [
    "## 3. Define scenarios\n",
    "\n",
    "Since the eight tier 1 & tier 2 SSPs are shipped with RCMIP, and they are quite familiar, we'll use these scenarios. We'll use the `fill_from_rcmip()` function from FaIR, so these have to use the same scenario names that appear in the RCMIP database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd63291",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\"ssp119\", \"ssp126\", \"ssp245\", \"ssp370\", \"ssp434\", \"ssp460\", \"ssp534-over\", \"ssp585\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71897df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.define_scenarios(scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb4614",
   "metadata": {},
   "source": [
    "## 4. Define configs\n",
    "\n",
    "The constrained dataset contains 1001 ensemble members, and 47 parameters that define the climate response of FaIR. The parameters pertain to `climate_configs` and `species_configs` that produce a wide range of climate responses. We sample from the 11 `climate_configs` parameters that define the [stochastic three-layer energy balance model](https://journals.ametsoc.org/view/journals/clim/33/18/jcliD190589.xml), plus a random seed. Of the other 35 parameters, three vary the behaviour of solar and volcanic forcing and are applied externally. The other 32 vary the behaviour of individual species and override default values of `species_configs` within FaIR (an example being the parameters defining the sensitivity of the carbon cycle feedbacks). Since every species has about 30 configs attached, there's well over a thousand potential parameters that could be modified in FaIR. Outside of the 32 parameters sampled, changing from default values would make little difference, would not be relevant to a particular species, or not be sensible to change.\n",
    "\n",
    "We'll use `pooch` to retrieve the v1.1 calibration data, and external datasets of solar and volcanic forcing that were pre-prepared for AR6 work.\n",
    "\n",
    "The name of the `config` axis will be an integer, which relates to the parameter draw from the large prior ensemble used in the calibration and constraining code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_params_1_1_0_obj = pooch.retrieve(\n",
    "    url = 'https://zenodo.org/record/7694879/files/calibrated_constrained_parameters.csv',\n",
    "    known_hash = 'md5:9f236c43dd18a36b7b63b94e05f3caab',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69688229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_configs = pd.read_csv(fair_params_1_1_0_obj, index_col=0)\n",
    "configs = df_configs.index  # this is used as a label for the \"config\" axis\n",
    "f.define_configs(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_configs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c2311",
   "metadata": {},
   "source": [
    "## 5. Define species and properties\n",
    "\n",
    "We will use FaIR's default list of 63 species. They are often run with default properties that are included in the model code. However, as part of the v1.1 calibration, some defaults are modified, such as the sensitivity of chemical precursors to methane lifetime. Rather than manually overriding this by setting `species_configs`, it is cleaner to modify the defaults in the CSV file that is read in to define the `species` and `properties`. \n",
    "\n",
    "In fact, as this only reads in and defines `species` and `properties` (not `species_configs`), the default (no `filename`) argument could be used here, but it is good practice in my opinion to put species, properties and configs in the same file, and to use the same file to read in `properties` and `species_configs`.\n",
    "\n",
    "If you're following along at home, feel free to insert a new cell after this one and inspect what the `species` and `properties` actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9fd4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "species, properties = read_properties(filename='data/species_configs_properties_calibration1.1.0.csv')\n",
    "f.define_species(species, properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ed144",
   "metadata": {},
   "source": [
    "## 6. Modify run options\n",
    "\n",
    "Not necessary, as we made all of our choices on initialisation (step 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e2a59",
   "metadata": {},
   "source": [
    "## 7. Create input and output xarrays\n",
    "\n",
    "If this runs without error, the problem is consistently and completely set up: we then just need to add data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.allocate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d7738",
   "metadata": {},
   "source": [
    "## 8. Fill in data\n",
    "\n",
    "### 8a. emissions, solar forcing, and volcanic forcing\n",
    "\n",
    "We can use the convenience function `fill_from_rcmip()` to fill in the emissions. Remember that not all `species` are things that take emissions, so if you see NaNs below, don't panic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd434bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fill_from_rcmip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352537fd",
   "metadata": {},
   "source": [
    "There is an issue with the RCMIP NOx emissions; the units are different for biomass burning emissions (Tg NO/yr) to the other emissions from fossil fuels, industry and agriculture (Tg NO2/yr). v1.1 of the calibration uses the corrected NOx emissions expressed in Tg NO2/yr, so we also have to correct them in FaIR for consistency.\n",
    "\n",
    "We download the RCMIP emissions file, and pull out the relevant sectors, update the unit, and finally override the correct entry of `f.emissions`.\n",
    "\n",
    "Notes on the below:\n",
    "- 46.006 is the molecular weight of NO2 (g/mol).\n",
    "- 30.006 is the molecular weight of NO (g/mol).\n",
    "- The final `[:550, None]` is to transfer the data coming in from RCMIP (dimension (750,), a timeseries of annual emissions) into the correct shape for our problem (550, 1001). Since we are looping over the `scenario` dimension and selecting it, and we are selecting NOx from the `species` dimension, these axes are collapsed and we're left with (`timepoints`, `configs`). The RCMIP data starts in 1750 as does our emissions data; if there is a mismatch in the start date, it would be necessary to select the correct slice from the RCMIP `DataFrame` that is loaded in. For a reminder of the dimensioning in FaIR 2.1, see https://docs.fairmodel.net/en/latest/intro.html#dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmip_emissions_file = pooch.retrieve(\n",
    "    url=\"doi:10.5281/zenodo.4589756/rcmip-emissions-annual-means-v5-1-0.csv\",\n",
    "    known_hash=\"md5:4044106f55ca65b094670e7577eaf9b3\",\n",
    ")\n",
    "df_emis = pd.read_csv(rcmip_emissions_file)\n",
    "gfed_sectors = [\n",
    "    \"Emissions|NOx|MAGICC AFOLU|Agricultural Waste Burning\",\n",
    "    \"Emissions|NOx|MAGICC AFOLU|Forest Burning\",\n",
    "    \"Emissions|NOx|MAGICC AFOLU|Grassland Burning\",\n",
    "    \"Emissions|NOx|MAGICC AFOLU|Peat Burning\",\n",
    "]\n",
    "for scenario in scenarios:\n",
    "    f.emissions.loc[dict(specie=\"NOx\", scenario=scenario)] = (\n",
    "        df_emis.loc[\n",
    "            (df_emis[\"Scenario\"] == scenario)\n",
    "            & (df_emis[\"Region\"] == \"World\")\n",
    "            & (df_emis[\"Variable\"].isin(gfed_sectors)),\n",
    "            \"1750\":\"2300\",\n",
    "        ]\n",
    "        .interpolate(axis=1)\n",
    "        .values.squeeze()\n",
    "        .sum(axis=0)\n",
    "        * 46.006\n",
    "        / 30.006\n",
    "        + df_emis.loc[\n",
    "            (df_emis[\"Scenario\"] == scenario)\n",
    "            & (df_emis[\"Region\"] == \"World\")\n",
    "            & (df_emis[\"Variable\"] == \"Emissions|NOx|MAGICC AFOLU|Agriculture\"),\n",
    "            \"1750\":\"2300\",\n",
    "        ]\n",
    "        .interpolate(axis=1)\n",
    "        .values.squeeze()\n",
    "        + df_emis.loc[\n",
    "            (df_emis[\"Scenario\"] == scenario)\n",
    "            & (df_emis[\"Region\"] == \"World\")\n",
    "            & (df_emis[\"Variable\"] == \"Emissions|NOx|MAGICC Fossil and Industrial\"),\n",
    "            \"1750\":\"2300\",\n",
    "        ]\n",
    "        .interpolate(axis=1)\n",
    "        .values.squeeze()\n",
    "    )[:550, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb7c3c",
   "metadata": {},
   "source": [
    "Now we fetch and fill in the solar and volcanic forcing. As these are forcing-driven time series, if we want to vary the uncertainties in the forcing, this has to happen before FaIR is run (see https://github.com/OMS-NetZero/FAIR/issues/126)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b03843",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_obj = pooch.retrieve(\n",
    "    url = 'https://raw.githubusercontent.com/chrisroadmap/fair-add-hfc/main/data/solar_erf_timebounds.csv',\n",
    "    known_hash = 'md5:98f6f4c5309d848fea89803683441acf',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3390e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "volcanic_obj = pooch.retrieve(\n",
    "    url = 'https://raw.githubusercontent.com/chrisroadmap/fair-add-hfc/main/data/volcanic_ERF_monthly_174901-201912.csv',\n",
    "    known_hash = 'md5:d3ac469ee7d2c2c75fbb656c2c67c4aa',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar = pd.read_csv(solar_obj, index_col=\"year\")\n",
    "df_volcanic = pd.read_csv(volcanic_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91dbe96",
   "metadata": {},
   "source": [
    "Remembering that everything that is not emissions is on `timebounds`, there is always one more `timebounds` than `timepoints`, so we define arrays of length 551 (1750 to 2300, inclusive).\n",
    "\n",
    "Volcanic forcing is given monthly, so we average the 12 previous months for each `timebounds` volcanic forcing.\n",
    "\n",
    "Volcanic forcing here follows the CMIP6 ScenarioMIP convention of a 10 year ramp down to zero from the last year of data (here 2019). Again a little bit of ninja skill with indexing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_forcing = np.zeros(551)\n",
    "volcanic_forcing = np.zeros(551)\n",
    "for i, year in enumerate(np.arange(1750, 2021)):\n",
    "    volcanic_forcing[i] = np.mean(\n",
    "        df_volcanic.loc[\n",
    "            ((year - 1) <= df_volcanic[\"year\"]) & (df_volcanic[\"year\"] < year)\n",
    "        ].erf\n",
    "    )\n",
    "volcanic_forcing[271:281] = np.linspace(1, 0, 10) * volcanic_forcing[270]\n",
    "solar_forcing = df_solar[\"erf\"].loc[1750:2300].values\n",
    "\n",
    "trend_shape = np.ones(551)\n",
    "trend_shape[:271] = np.linspace(0, 1, 271)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ef345",
   "metadata": {},
   "source": [
    "We then use our calibrated, constrained ensemble to individually scale the volcanic forcing time series, and the solar amplitude and trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2fc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(\n",
    "    f.forcing,\n",
    "    volcanic_forcing[:, None, None] * df_configs[\"scale Volcanic\"].values.squeeze(),\n",
    "    specie=\"Volcanic\",\n",
    ")\n",
    "fill(\n",
    "    f.forcing,\n",
    "    solar_forcing[:, None, None] * df_configs[\"solar_amplitude\"].values.squeeze()\n",
    "    + trend_shape[:, None, None] * df_configs[\"solar_trend\"].values.squeeze(),\n",
    "    specie=\"Solar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f490ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.forcing.loc[dict(specie=\"Solar\", scenario=\"ssp245\")]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3fd73",
   "metadata": {},
   "source": [
    "### 8b. Fill in climate_configs\n",
    "\n",
    "This is relatively straightforward from the calibrated, constrained dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6cb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(f.climate_configs[\"ocean_heat_capacity\"], df_configs.loc[:, \"c1\":\"c3\"].values)\n",
    "fill(\n",
    "    f.climate_configs[\"ocean_heat_transfer\"],\n",
    "    df_configs.loc[:, \"kappa1\":\"kappa3\"].values,\n",
    ")\n",
    "fill(f.climate_configs[\"deep_ocean_efficacy\"], df_configs[\"epsilon\"].values.squeeze())\n",
    "fill(f.climate_configs[\"gamma_autocorrelation\"], df_configs[\"gamma\"].values.squeeze())\n",
    "fill(f.climate_configs[\"sigma_eta\"], df_configs[\"sigma_eta\"].values.squeeze())\n",
    "fill(f.climate_configs[\"sigma_xi\"], df_configs[\"sigma_xi\"].values.squeeze())\n",
    "fill(f.climate_configs[\"seed\"], df_configs[\"seed\"])\n",
    "fill(f.climate_configs[\"stochastic_run\"], True)\n",
    "fill(f.climate_configs[\"use_seed\"], True)\n",
    "fill(f.climate_configs[\"forcing_4co2\"], df_configs[\"F_4xCO2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c67b5e",
   "metadata": {},
   "source": [
    "### 8c. Fill in species_configs\n",
    "\n",
    "Firstly we want to get the defaults from our new species/properties/configs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798edffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fill_species_configs(filename='data/species_configs_properties_calibration1.1.0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792ce8b",
   "metadata": {},
   "source": [
    "Then, we overwrite the `species_configs` that are varies as part of the probablistic sampling. This makes heavy use of the `fill()` convenience function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a66859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carbon cycle\n",
    "fill(f.species_configs[\"iirf_0\"], df_configs[\"r0\"].values.squeeze(), specie=\"CO2\")\n",
    "fill(f.species_configs[\"iirf_airborne\"], df_configs[\"rA\"].values.squeeze(), specie=\"CO2\")\n",
    "fill(f.species_configs[\"iirf_uptake\"], df_configs[\"rU\"].values.squeeze(), specie=\"CO2\")\n",
    "fill(f.species_configs[\"iirf_temperature\"], df_configs[\"rT\"].values.squeeze(), specie=\"CO2\")\n",
    "\n",
    "# aerosol indirect\n",
    "fill(f.species_configs[\"aci_scale\"], df_configs[\"beta\"].values.squeeze())\n",
    "fill(f.species_configs[\"aci_shape\"], df_configs[\"shape Sulfur\"].values.squeeze(), specie=\"Sulfur\")\n",
    "fill(f.species_configs[\"aci_shape\"], df_configs[\"shape BC\"].values.squeeze(), specie=\"BC\")\n",
    "fill(f.species_configs[\"aci_shape\"], df_configs[\"shape OC\"].values.squeeze(), specie=\"OC\")\n",
    "\n",
    "# aerosol direct\n",
    "for specie in [\n",
    "    \"BC\", \n",
    "    \"CH4\", \n",
    "    \"N2O\",\n",
    "    \"NH3\", \n",
    "    \"NOx\",\n",
    "    \"OC\", \n",
    "    \"Sulfur\", \n",
    "    \"VOC\",\n",
    "    \"Equivalent effective stratospheric chlorine\"\n",
    "]:\n",
    "    fill(f.species_configs[\"erfari_radiative_efficiency\"], df_configs[f\"ari {specie}\"], specie=specie)\n",
    "\n",
    "# forcing scaling\n",
    "for specie in [\n",
    "    \"CO2\", \n",
    "    \"CH4\", \n",
    "    \"N2O\", \n",
    "    \"Stratospheric water vapour\",\n",
    "    \"Contrails\", \n",
    "    \"Light absorbing particles on snow and ice\", \n",
    "    \"Land use\"\n",
    "]:\n",
    "    fill(f.species_configs[\"forcing_scale\"], df_configs[f\"scale {specie}\"].values.squeeze(), specie=specie)\n",
    "# the halogenated gases all take the same scale factor\n",
    "for specie in [\n",
    "    \"CFC-11\",\n",
    "    \"CFC-12\",\n",
    "    \"CFC-113\",\n",
    "    \"CFC-114\",\n",
    "    \"CFC-115\",\n",
    "    \"HCFC-22\",\n",
    "    \"HCFC-141b\",\n",
    "    \"HCFC-142b\",\n",
    "    \"CCl4\",\n",
    "    \"CHCl3\",\n",
    "    \"CH2Cl2\",\n",
    "    \"CH3Cl\",\n",
    "    \"CH3CCl3\",\n",
    "    \"CH3Br\",\n",
    "    \"Halon-1211\",\n",
    "    \"Halon-1301\",\n",
    "    \"Halon-2402\",\n",
    "    \"CF4\",\n",
    "    \"C2F6\",\n",
    "    \"C3F8\",\n",
    "    \"c-C4F8\",\n",
    "    \"C4F10\",\n",
    "    \"C5F12\",\n",
    "    \"C6F14\",\n",
    "    \"C7F16\",\n",
    "    \"C8F18\",\n",
    "    \"NF3\",\n",
    "    \"SF6\",\n",
    "    \"SO2F2\",\n",
    "    \"HFC-125\",\n",
    "    \"HFC-134a\",\n",
    "    \"HFC-143a\",\n",
    "    \"HFC-152a\",\n",
    "    \"HFC-227ea\",\n",
    "    \"HFC-23\",\n",
    "    \"HFC-236fa\",\n",
    "    \"HFC-245fa\",\n",
    "    \"HFC-32\",\n",
    "    \"HFC-365mfc\",\n",
    "    \"HFC-4310mee\",\n",
    "]:\n",
    "    fill(f.species_configs[\"forcing_scale\"], df_configs[\"scale minorGHG\"].values.squeeze(), specie=specie)\n",
    "\n",
    "# ozone\n",
    "for specie in [\"CH4\", \"N2O\", \"Equivalent effective stratospheric chlorine\", \"CO\", \"VOC\", \"NOx\"]:\n",
    "    fill(f.species_configs[\"ozone_radiative_efficiency\"], df_configs[f\"o3 {specie}\"], specie=specie)\n",
    "\n",
    "# initial value of CO2 concentration (but not baseline for forcing calculations)\n",
    "fill(\n",
    "    f.species_configs[\"baseline_concentration\"], \n",
    "    df_configs[\"co2_concentration_1750\"].values.squeeze(), \n",
    "    specie=\"CO2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0bfb6",
   "metadata": {},
   "source": [
    "### 8d. Initial conditions\n",
    "\n",
    "It's important these are defined, as they are NaN by default, and it's likely you'll run into problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise(f.concentration, f.species_configs[\"baseline_concentration\"])\n",
    "initialise(f.forcing, 0)\n",
    "initialise(f.temperature, 0)\n",
    "initialise(f.cumulative_emissions, 0)\n",
    "initialise(f.airborne_emissions, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b948f5",
   "metadata": {},
   "source": [
    "## 9. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52b560",
   "metadata": {},
   "source": [
    "## 10. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c51d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_titles = {\n",
    "    \"ssp119\": \"SSP1-1.9\",\n",
    "    \"ssp126\": \"SSP1-2.6\",\n",
    "    \"ssp245\": \"SSP2-4.5\",\n",
    "    \"ssp370\": \"SSP3-7.0\",\n",
    "    \"ssp434\": \"SSP4-3.4\",\n",
    "    \"ssp460\": \"SSP4-6.0\",\n",
    "    \"ssp534-over\": \"SSP5-3.4-overshoot\",\n",
    "    \"ssp585\": \"SSP5-8.5\",\n",
    "}\n",
    "\n",
    "ar6_colors = {\n",
    "    \"ssp119\": \"#00a9cf\",\n",
    "    \"ssp126\": \"#003466\",\n",
    "    \"ssp245\": \"#f69320\",\n",
    "    \"ssp370\": \"#df0000\",\n",
    "    \"ssp434\": \"#2274ae\",\n",
    "    \"ssp460\": \"#b0724e\",\n",
    "    \"ssp534-over\": \"#92397a\",\n",
    "    \"ssp585\": \"#980002\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9745f",
   "metadata": {},
   "source": [
    "### Temperature anomaly\n",
    "\n",
    "We define an anomaly baseline of 1850-1900. This is 51 complete years. As FaIR temperature anomalies are on `timebounds`, we take mid-year temperatures as averages of the bounding `timebounds`; so, 1850.5 is an average of 1850.0 and 1851.0. It means we take an average period of 1850-1901 timebounds with 0.5 weights for 1850 and 1901 and 1.0 weights for other `timebounds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_51yr = np.ones(52)\n",
    "weights_51yr[0] = 0.5\n",
    "weights_51yr[-1] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    for pp in ((0, 100), (5, 95), (16, 84)):\n",
    "        ax[i // 4, i % 4].fill_between(\n",
    "            f.timebounds,\n",
    "            np.percentile(\n",
    "                f.temperature.loc[dict(scenario=scenario, layer=0)]\n",
    "                - np.average(\n",
    "                    f.temperature.loc[\n",
    "                        dict(scenario=scenario, timebounds=np.arange(1850, 1902), layer=0)\n",
    "                    ],\n",
    "                    weights=weights_51yr,\n",
    "                    axis=0\n",
    "                ),\n",
    "                pp[0],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.percentile(\n",
    "                f.temperature.loc[dict(scenario=scenario, layer=0)]\n",
    "                - np.average(\n",
    "                    f.temperature.loc[\n",
    "                        dict(scenario=scenario, timebounds=np.arange(1850, 1902), layer=0)\n",
    "                    ],\n",
    "                    weights=weights_51yr,\n",
    "                    axis=0\n",
    "                ),\n",
    "                pp[1],\n",
    "                axis=1,\n",
    "            ),\n",
    "            color=ar6_colors[scenarios[i]],\n",
    "            alpha=0.2,\n",
    "            lw=0\n",
    "        )\n",
    "\n",
    "    ax[i // 4, i % 4].plot(\n",
    "        f.timebounds,\n",
    "        np.median(\n",
    "            f.temperature.loc[dict(scenario=scenario, layer=0)]\n",
    "            - np.average(\n",
    "                f.temperature.loc[\n",
    "                    dict(scenario=scenario, timebounds=np.arange(1850, 1902), layer=0)\n",
    "                ],\n",
    "                weights=weights_51yr,\n",
    "                axis=0\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "        color=ar6_colors[scenarios[i]],\n",
    "    )\n",
    "#     ax[i // 4, i % 4].plot(np.arange(1850.5, 2021), gmst, color=\"k\")\n",
    "    ax[i // 4, i % 4].set_xlim(1850, 2300)\n",
    "    ax[i // 4, i % 4].set_ylim(-1, 10)\n",
    "    ax[i // 4, i % 4].axhline(0, color=\"k\", ls=\":\", lw=0.5)\n",
    "    ax[i // 4, i % 4].set_title(fancy_titles[scenarios[i]])\n",
    "\n",
    "pl.suptitle(\"SSP temperature anomalies\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04067bf4",
   "metadata": {},
   "source": [
    "### CO2 concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    for pp in ((0, 100), (5, 95), (16, 84)):\n",
    "        ax[i // 4, i % 4].fill_between(\n",
    "            f.timebounds,\n",
    "            np.percentile(\n",
    "                f.concentration.loc[dict(scenario=scenario, specie='CO2')],\n",
    "                pp[0],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.percentile(\n",
    "                f.concentration.loc[dict(scenario=scenario, specie='CO2')],\n",
    "                pp[1],\n",
    "                axis=1,\n",
    "            ),\n",
    "            color=ar6_colors[scenarios[i]],\n",
    "            alpha=0.2,\n",
    "            lw=0\n",
    "        )\n",
    "\n",
    "    ax[i // 4, i % 4].plot(\n",
    "        f.timebounds,\n",
    "        np.median(\n",
    "            f.concentration.loc[dict(scenario=scenario, specie='CO2')],\n",
    "            axis=1,\n",
    "        ),\n",
    "        color=ar6_colors[scenarios[i]],\n",
    "    )\n",
    "    ax[i // 4, i % 4].set_xlim(1850, 2300)\n",
    "    ax[i // 4, i % 4].set_ylim(0, 2500)\n",
    "    ax[i // 4, i % 4].axhline(0, color=\"k\", ls=\":\", lw=0.5)\n",
    "    ax[i // 4, i % 4].set_title(fancy_titles[scenarios[i]])\n",
    "\n",
    "pl.suptitle(\"SSP CO$_2$ concentration\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7e7ca",
   "metadata": {},
   "source": [
    "### Total effective radiative forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    for pp in ((0, 100), (5, 95), (16, 84)):\n",
    "        ax[i // 4, i % 4].fill_between(\n",
    "            f.timebounds,\n",
    "            np.percentile(\n",
    "                f.forcing_sum.loc[dict(scenario=scenario)],\n",
    "                pp[0],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.percentile(\n",
    "                f.forcing_sum.loc[dict(scenario=scenario)],\n",
    "                pp[1],\n",
    "                axis=1,\n",
    "            ),\n",
    "            color=ar6_colors[scenarios[i]],\n",
    "            alpha=0.2,\n",
    "            lw=0\n",
    "        )\n",
    "\n",
    "    ax[i // 4, i % 4].plot(\n",
    "        f.timebounds,\n",
    "        np.median(\n",
    "            f.forcing_sum.loc[dict(scenario=scenario)],\n",
    "            axis=1,\n",
    "        ),\n",
    "        color=ar6_colors[scenarios[i]],\n",
    "    )\n",
    "    ax[i // 4, i % 4].set_xlim(1850, 2300)\n",
    "    ax[i // 4, i % 4].set_ylim(0, 15)\n",
    "    ax[i // 4, i % 4].axhline(0, color=\"k\", ls=\":\", lw=0.5)\n",
    "    ax[i // 4, i % 4].set_title(fancy_titles[scenarios[i]])\n",
    "\n",
    "pl.suptitle(\"SSP effective radiative forcing\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a293e",
   "metadata": {},
   "source": [
    "### CO2 airborne fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48660087",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    for pp in ((0, 100), (5, 95), (16, 84)):\n",
    "        ax[i // 4, i % 4].fill_between(\n",
    "            f.timebounds,\n",
    "            np.percentile(\n",
    "                f.airborne_fraction.loc[dict(scenario=scenario, specie='CO2')],\n",
    "                pp[0],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.percentile(\n",
    "                f.airborne_fraction.loc[dict(scenario=scenario, specie='CO2')],\n",
    "                pp[1],\n",
    "                axis=1,\n",
    "            ),\n",
    "            color=ar6_colors[scenarios[i]],\n",
    "            alpha=0.2,\n",
    "            lw=0\n",
    "        )\n",
    "\n",
    "    ax[i // 4, i % 4].plot(\n",
    "        f.timebounds,\n",
    "        np.median(\n",
    "            f.airborne_fraction.loc[dict(scenario=scenario, specie='CO2')],\n",
    "            axis=1,\n",
    "        ),\n",
    "        color=ar6_colors[scenarios[i]],\n",
    "    )\n",
    "    ax[i // 4, i % 4].set_xlim(1850, 2300)\n",
    "    ax[i // 4, i % 4].set_ylim(0, 1)\n",
    "    ax[i // 4, i % 4].axhline(0, color=\"k\", ls=\":\", lw=0.5)\n",
    "    ax[i // 4, i % 4].set_title(fancy_titles[scenarios[i]])\n",
    "\n",
    "pl.suptitle(\"SSP CO$_2$ airborne fraction\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    for pp in ((0, 100), (5, 95), (16, 84)):\n",
    "        ax[i // 4, i % 4].fill_between(\n",
    "            f.timebounds,\n",
    "            np.percentile(\n",
    "                f.ocean_heat_content_change.loc[dict(scenario=scenario)],\n",
    "                pp[0],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.percentile(\n",
    "                f.ocean_heat_content_change.loc[dict(scenario=scenario)],\n",
    "                pp[1],\n",
    "                axis=1,\n",
    "            ),\n",
    "            color=ar6_colors[scenarios[i]],\n",
    "            alpha=0.2,\n",
    "            lw=0\n",
    "        )\n",
    "\n",
    "    ax[i // 4, i % 4].plot(\n",
    "        f.timebounds,\n",
    "        np.median(\n",
    "            f.ocean_heat_content_change.loc[dict(scenario=scenario)],\n",
    "            axis=1,\n",
    "        ),\n",
    "        color=ar6_colors[scenarios[i]],\n",
    "    )\n",
    "    ax[i // 4, i % 4].set_xlim(1850, 2300)\n",
    "    ax[i // 4, i % 4].set_ylim(0, 1e25)\n",
    "    ax[i // 4, i % 4].axhline(0, color=\"k\", ls=\":\", lw=0.5)\n",
    "    ax[i // 4, i % 4].set_title(fancy_titles[scenarios[i]])\n",
    "\n",
    "pl.suptitle(\"SSP Earth energy uptake\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c529915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
